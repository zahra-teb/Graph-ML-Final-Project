{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHMb7cpT3E3Q",
        "outputId": "039ed578-8a37-46b7-9f02-05d107773da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl\n",
            "  Downloading dgl-1.1.1-cp310-cp310-manylinux1_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl -f https://data.dgl.ai/wheels/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11EEpcpRVjP9",
        "outputId": "88185212-befe-4be0-fdd6-dfc016d5be49"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.7.0)\n",
            "Collecting isort>=5.10.1 (from dglgo)\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n",
            "  Downloading autopep8-2.0.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m502.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpydoc>=1.1.0 (from dglgo)\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.9)\n",
            "Collecting ruamel.yaml>=0.17.20 (from dglgo)\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0)\n",
            "Collecting ogb>=1.3.3 (from dglgo)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit-pypi (from dglgo)\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Collecting sphinx>=4.2 (from numpydoc>=1.1.0->dglgo)\n",
            "  Downloading sphinx-7.0.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.26.16)\n",
            "Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.6.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Collecting docutils<0.21,>=0.18.1 (from sphinx>=4.2->numpydoc>=1.1.0->dglgo)\n",
            "  Downloading docutils-0.20.1-py3-none-any.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=2b069ab9612cef21bcb253b2007ded5d88ab73c84785e45a850f2fd745024ea1\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, docutils, sphinx, ruamel.yaml, outdated, autopep8, numpydoc, ogb, dglgo\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "Successfully installed autopep8-2.0.2 dglgo-0.0.2 docutils-0.20.1 isort-5.12.0 littleutils-0.2.2 numpydoc-1.5.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.10.0 rdkit-pypi-2022.9.5 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 sphinx-7.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn\n",
        "import torch.nn.functional as F\n",
        "import shutil\n",
        "from torch.utils.data import DataLoader\n",
        "import cloudpickle\n",
        "from dgl.nn import GraphConv\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "PeNk-YaEVmzC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEbZysGyVrzw",
        "outputId": "b301691d-6898-41eb-bec1-8f5cdb997aa9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir FreeSolv_dataset"
      ],
      "metadata": {
        "id": "umWYuaPdV1J2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/freesolv.zip -d FreeSolv_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNkLH0jFWCIR",
        "outputId": "a80d0646-46af-4f81-e529-e6a166a11db7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/freesolv.zip\n",
            "  inflating: FreeSolv_dataset/scaffold_0_smiles_train.pickle  \n",
            "  inflating: FreeSolv_dataset/scaffold_0_test.bin  \n",
            "  inflating: FreeSolv_dataset/scaffold_0_val.bin  \n",
            "  inflating: FreeSolv_dataset/scaffold_0_smiles_val.pickle  \n",
            "  inflating: FreeSolv_dataset/scaffold_0_smiles_test.pickle  \n",
            "  inflating: FreeSolv_dataset/scaffold_0_train.bin  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_dir = \"./\"\n",
        "checkpoint_path = current_dir + \"save_models/model_checkpoints/\" + \"checkpoint\"\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "best_model_path = current_dir + \"save_models/best_model/\"\n",
        "\n",
        "folder_data_temp = current_dir +\"data_temp/\"\n",
        "shutil.rmtree(folder_data_temp, ignore_errors=True)"
      ],
      "metadata": {
        "id": "T49Lw3mEWLLP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom PyTorch Dataset"
      ],
      "metadata": {
        "id": "UrHwUNqJWYFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Regression Dataset \"\"\"\n",
        "class DGLDatasetReg(torch.utils.data.Dataset):\n",
        "    def __init__(self, address, transform=None, train=False, scaler=None):\n",
        "            self.train = train\n",
        "            self.scaler = scaler\n",
        "            self.data_set, train_labels_masks_globals = dgl.load_graphs(address+\".bin\")\n",
        "            num_graphs = len(self.data_set)\n",
        "            self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs,-1)\n",
        "            self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs,-1)\n",
        "            self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs,-1)\n",
        "            self.transform = transform\n",
        "\n",
        "    def scaler_method(self):\n",
        "        if self.train:\n",
        "            scaler = StandardScaler().fit(self.labels)\n",
        "            self.scaler = scaler\n",
        "        return self.scaler\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_set)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return  self.data_set[idx], torch.tensor(self.scaler.transform(self.labels)[idx]).float(), self.masks[idx], self.globals[idx]"
      ],
      "metadata": {
        "id": "iZlE0qxoWThF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining Train, Validation and Test sets"
      ],
      "metadata": {
        "id": "M_nSer_NXtWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_data_temp =  'FreeSolv_dataset/scaffold_0'\n",
        "train_set = DGLDatasetReg(address=path_data_temp+\"_train\", train=True)\n",
        "scaler = train_set.scaler_method()\n",
        "val_set = DGLDatasetReg(address=path_data_temp+\"_val\", scaler=scaler)\n",
        "test_set = DGLDatasetReg(address=path_data_temp+\"_test\", scaler=scaler)\n",
        "\n",
        "print('Train set size: ', len(train_set))\n",
        "print('Validation set size: ', len(val_set))\n",
        "print('Test set size: ', len(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE-QWwseXoCQ",
        "outputId": "1be7f441-1d56-4948-c4c9-d6ac5a17ec8e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size:  513\n",
            "Validation set size:  64\n",
            "Test set size:  65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DataLoader"
      ],
      "metadata": {
        "id": "UTajcFTKYKj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(batch):\n",
        "    # batch is a list of tuples (graphs, labels, masks, globals)\n",
        "    # Concatenate a sequence of graphs\n",
        "    graphs = [e[0] for e in batch]\n",
        "    g = dgl.batch(graphs)\n",
        "\n",
        "    # Concatenate a sequence of tensors (labels) along a new dimension\n",
        "    labels = [e[1] for e in batch]\n",
        "    labels = torch.stack(labels, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (masks) along a new dimension\n",
        "    masks = [e[2] for e in batch]\n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (globals) along a new dimension\n",
        "    globals = [e[3] for e in batch]\n",
        "    globals = torch.stack(globals, 0)\n",
        "\n",
        "    return g, labels, masks, globals\n",
        "\n",
        "\n",
        "def loader(batch_size=64):\n",
        "    train_dataloader = DataLoader(train_set,\n",
        "                              batch_size=batch_size,\n",
        "                              collate_fn=collate,\n",
        "                              drop_last=True,\n",
        "                              shuffle=True,\n",
        "                              num_workers=1)\n",
        "\n",
        "    val_dataloader =  DataLoader(val_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=True,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=True,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "upputhuEX-kJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = loader(batch_size=64)"
      ],
      "metadata": {
        "id": "Rf6FvxT93ooH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Some variables"
      ],
      "metadata": {
        "id": "QqUeyJUY-usO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FreeSolv dataset has 1 task. Some other datasets may have some more number of tasks, e.g., tox21 has 12 tasks.\n",
        "num_tasks = 1\n",
        "\n",
        "# Size of global feature of each graph\n",
        "global_size = 200\n",
        "\n",
        "# Number of epochs to train the model\n",
        "num_epochs = 100\n",
        "\n",
        "# Number of steps to wait if the model performance on the validation set does not improve\n",
        "patience = 10\n",
        "\n",
        "#Configurations to instantiate the model\n",
        "config = {\"node_feature_size\":127, \"edge_feature_size\":12, \"hidden_size\":100}\n"
      ],
      "metadata": {
        "id": "qWH8d7Pz-ycr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function in order to computing score(RMSE)"
      ],
      "metadata": {
        "id": "NVHfeUVv1IQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "    final_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "            labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "            loss = loss_sum(prediction, labels)\n",
        "            final_loss += loss.item()\n",
        "        final_loss /= val_size\n",
        "        final_loss = math.sqrt(final_loss) # RMSE\n",
        "    return final_loss / num_tasks\n"
      ],
      "metadata": {
        "id": "_lEWwBEc1Sl4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss Function"
      ],
      "metadata": {
        "id": "IPC1gZR19GaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "UkgJHzv09Wsn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "CJkXkfaB860l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "\n",
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "\n",
        "    return epoch_train_loss\n",
        "\n",
        "\n",
        "def train_evaluate(model):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = np.Inf\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint!\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ],
      "metadata": {
        "id": "cqwXCuXh8swj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Function to compute test set score of the final saved model"
      ],
      "metadata": {
        "id": "rmFhLl6q_yAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "def test_evaluate(model):\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    model.eval()\n",
        "    test_score = compute_score(model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ],
      "metadata": {
        "id": "jVFS1t4F1SYm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN"
      ],
      "metadata": {
        "id": "93qzXCUGzoqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GCN with two convolutional layers."
      ],
      "metadata": {
        "id": "z5W7c9ahzrvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN1(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree='True')\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree='True')\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "WZAvYYkz3wUF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train the models and evaluate their performance"
      ],
      "metadata": {
        "id": "3neWMxJ7AH-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = GCN1(config, global_size, num_tasks)"
      ],
      "metadata": {
        "id": "x5jbNoQCAADA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate(model_1)\n",
        "test_evaluate(model_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu2ZlmxQANvf",
        "outputId": "e643c4bb-aac9-429e-8930-171198d719d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint!\n",
            "Epoch: 1/100 | Training Loss: 0.987 | Valid Score: 3.810\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 0.965 | Valid Score: 3.836\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 0.950 | Valid Score: 3.867\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 4/100 | Training Loss: 0.929 | Valid Score: 3.889\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 5/100 | Training Loss: 0.920 | Valid Score: 3.904\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 6/100 | Training Loss: 0.909 | Valid Score: 3.907\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 7/100 | Training Loss: 0.898 | Valid Score: 3.914\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 8/100 | Training Loss: 0.888 | Valid Score: 3.917\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 9/100 | Training Loss: 0.877 | Valid Score: 3.914\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 10/100 | Training Loss: 0.868 | Valid Score: 3.909\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 11/100 | Training Loss: 0.859 | Valid Score: 3.906\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 3.810 \n",
            "\n",
            "Test Score: 3.632 \n",
            "\n",
            "Execution time: 6.116 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### GCN with 4 convolutional layers and batch normalization layers and dropouts."
      ],
      "metadata": {
        "id": "m0uFZz6uEq-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN2(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree='True')\n",
        "        self.bn1 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree='True')\n",
        "        self.bn2 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree='True')\n",
        "        self.bn3 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.dropout3 = nn.Dropout(0.2)\n",
        "\n",
        "        self.conv4 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree='True')\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = self.bn1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout1(h)\n",
        "\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = self.bn2(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout2(h)\n",
        "\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = self.bn3(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout3(h)\n",
        "\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "t7dFPPDbAmrM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = GCN2(config, global_size, num_tasks)"
      ],
      "metadata": {
        "id": "HXmQCTESEvkz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate(model_2)\n",
        "test_evaluate(model_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f91V8FNEyMR",
        "outputId": "2b050e85-73d0-440c-fefc-6c782f531d9b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint!\n",
            "Epoch: 1/100 | Training Loss: 1.405 | Valid Score: 4.262\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.262 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 2/100 | Training Loss: 1.319 | Valid Score: 4.135\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.135 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 3/100 | Training Loss: 1.198 | Valid Score: 4.133\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 4.133 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 4/100 | Training Loss: 1.108 | Valid Score: 4.182\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 4.133 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 5/100 | Training Loss: 1.104 | Valid Score: 4.214\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 4.133 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 6/100 | Training Loss: 1.050 | Valid Score: 4.233\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 4.133 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 7/100 | Training Loss: 1.026 | Valid Score: 4.170\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 4.133 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 8/100 | Training Loss: 1.014 | Valid Score: 4.144\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 4.133 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 9/100 | Training Loss: 0.950 | Valid Score: 4.120\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 4.120 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 10/100 | Training Loss: 0.986 | Valid Score: 4.077\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 4.077 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 11/100 | Training Loss: 0.954 | Valid Score: 4.036\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 4.036 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 12/100 | Training Loss: 0.843 | Valid Score: 4.044\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 4.036 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 13/100 | Training Loss: 0.989 | Valid Score: 3.979\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 3.979 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 14/100 | Training Loss: 0.869 | Valid Score: 3.953\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 3.953 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 15/100 | Training Loss: 0.934 | Valid Score: 3.907\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 3.907 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 16/100 | Training Loss: 0.878 | Valid Score: 3.869\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 3.869 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 17/100 | Training Loss: 0.830 | Valid Score: 3.803\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 3.803 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 18/100 | Training Loss: 0.814 | Valid Score: 3.795\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 3.795 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 19/100 | Training Loss: 0.791 | Valid Score: 3.775\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 3.775 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 20/100 | Training Loss: 0.803 | Valid Score: 3.771\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 3.771 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 21/100 | Training Loss: 0.697 | Valid Score: 3.688\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 3.688 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 22/100 | Training Loss: 0.768 | Valid Score: 3.655\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 3.655 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 23/100 | Training Loss: 0.807 | Valid Score: 3.647\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 3.647 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 24/100 | Training Loss: 0.744 | Valid Score: 3.612\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 3.612 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 25/100 | Training Loss: 0.717 | Valid Score: 3.578\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 3.578 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 26/100 | Training Loss: 0.773 | Valid Score: 3.538\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 3.538 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 27/100 | Training Loss: 0.719 | Valid Score: 3.540\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 3.538 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 28/100 | Training Loss: 0.732 | Valid Score: 3.499\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 3.499 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 29/100 | Training Loss: 0.695 | Valid Score: 3.514\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 3.499 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 30/100 | Training Loss: 0.720 | Valid Score: 3.488\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 3.488 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 31/100 | Training Loss: 0.671 | Valid Score: 3.486\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 3.486 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 32/100 | Training Loss: 0.717 | Valid Score: 3.435\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 3.435 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 33/100 | Training Loss: 0.746 | Valid Score: 3.399\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 3.399 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 34/100 | Training Loss: 0.723 | Valid Score: 3.391\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 3.391 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 35/100 | Training Loss: 0.684 | Valid Score: 3.359\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 3.359 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 36/100 | Training Loss: 0.678 | Valid Score: 3.357\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 3.357 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 37/100 | Training Loss: 0.669 | Valid Score: 3.364\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 3.357 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 38/100 | Training Loss: 0.638 | Valid Score: 3.356\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 3.356 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 39/100 | Training Loss: 0.699 | Valid Score: 3.328\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 3.328 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 0.658 | Valid Score: 3.339\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 3.328 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 41/100 | Training Loss: 0.714 | Valid Score: 3.343\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 3.328 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 42/100 | Training Loss: 0.670 | Valid Score: 3.371\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 3.328 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 43/100 | Training Loss: 0.668 | Valid Score: 3.362\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 3.328 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 44/100 | Training Loss: 0.674 | Valid Score: 3.324\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 3.324 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 45/100 | Training Loss: 0.648 | Valid Score: 3.279\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 3.279 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 46/100 | Training Loss: 0.657 | Valid Score: 3.266\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 3.266 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 47/100 | Training Loss: 0.637 | Valid Score: 3.242\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 3.242 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 48/100 | Training Loss: 0.683 | Valid Score: 3.274\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 3.242 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 49/100 | Training Loss: 0.600 | Valid Score: 3.250\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 3.242 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 50/100 | Training Loss: 0.601 | Valid Score: 3.261\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 3.242 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 51/100 | Training Loss: 0.590 | Valid Score: 3.227\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 3.227 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 52/100 | Training Loss: 0.596 | Valid Score: 3.181\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 3.181 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 53/100 | Training Loss: 0.639 | Valid Score: 3.194\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 3.181 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 54/100 | Training Loss: 0.584 | Valid Score: 3.188\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 3.181 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 55/100 | Training Loss: 0.582 | Valid Score: 3.207\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 3.181 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 56/100 | Training Loss: 0.600 | Valid Score: 3.144\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 3.144 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 57/100 | Training Loss: 0.576 | Valid Score: 3.101\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 3.101 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 58/100 | Training Loss: 0.590 | Valid Score: 3.094\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 3.094 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 59/100 | Training Loss: 0.583 | Valid Score: 3.110\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 3.094 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 60/100 | Training Loss: 0.577 | Valid Score: 3.110\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 3.094 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 61/100 | Training Loss: 0.594 | Valid Score: 3.130\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 3.094 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 62/100 | Training Loss: 0.613 | Valid Score: 3.115\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 3.094 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 63/100 | Training Loss: 0.585 | Valid Score: 3.152\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 3.094 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 64/100 | Training Loss: 0.625 | Valid Score: 3.162\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 3.094 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 65/100 | Training Loss: 0.547 | Valid Score: 3.139\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 3.094 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 66/100 | Training Loss: 0.577 | Valid Score: 3.151\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 3.094 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 67/100 | Training Loss: 0.552 | Valid Score: 3.083\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 3.083 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 68/100 | Training Loss: 0.563 | Valid Score: 3.075\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 3.075 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 69/100 | Training Loss: 0.545 | Valid Score: 3.018\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 3.018 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 70/100 | Training Loss: 0.577 | Valid Score: 3.018\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 3.018 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 71/100 | Training Loss: 0.541 | Valid Score: 3.009\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 3.009 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 72/100 | Training Loss: 0.574 | Valid Score: 3.001\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 3.001 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 73/100 | Training Loss: 0.539 | Valid Score: 2.986\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 2.986 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 74/100 | Training Loss: 0.579 | Valid Score: 2.993\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 2.986 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 75/100 | Training Loss: 0.557 | Valid Score: 2.991\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 2.986 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 76/100 | Training Loss: 0.501 | Valid Score: 2.985\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 2.985 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 77/100 | Training Loss: 0.541 | Valid Score: 2.983\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 2.983 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 78/100 | Training Loss: 0.541 | Valid Score: 3.024\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 2.983 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 79/100 | Training Loss: 0.559 | Valid Score: 3.016\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 2.983 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 80/100 | Training Loss: 0.565 | Valid Score: 2.969\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 2.969 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 81/100 | Training Loss: 0.513 | Valid Score: 3.034\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 2.969 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 82/100 | Training Loss: 0.500 | Valid Score: 3.035\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 2.969 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 83/100 | Training Loss: 0.512 | Valid Score: 3.038\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 2.969 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 84/100 | Training Loss: 0.560 | Valid Score: 2.972\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 2.969 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 85/100 | Training Loss: 0.564 | Valid Score: 2.962\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 2.962 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 86/100 | Training Loss: 0.577 | Valid Score: 2.953\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 2.953 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 87/100 | Training Loss: 0.554 | Valid Score: 2.958\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 2.953 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 88/100 | Training Loss: 0.501 | Valid Score: 2.959\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 2.953 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 89/100 | Training Loss: 0.524 | Valid Score: 2.950\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 2.950 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 90/100 | Training Loss: 0.511 | Valid Score: 2.894\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 2.894 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 91/100 | Training Loss: 0.506 | Valid Score: 2.897\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 2.894 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 92/100 | Training Loss: 0.505 | Valid Score: 2.888\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 2.888 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 93/100 | Training Loss: 0.514 | Valid Score: 2.925\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 2.888 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 94/100 | Training Loss: 0.518 | Valid Score: 2.908\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 2.888 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 95/100 | Training Loss: 0.498 | Valid Score: 2.886\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 2.886 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 96/100 | Training Loss: 0.516 | Valid Score: 2.823\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 2.823 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 97/100 | Training Loss: 0.535 | Valid Score: 2.858\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 2.823 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 98/100 | Training Loss: 0.517 | Valid Score: 2.827\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 2.823 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 99/100 | Training Loss: 0.500 | Valid Score: 2.797\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 2.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 100/100 | Training Loss: 0.482 | Valid Score: 2.832\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 2.797 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 2.797 \n",
            "\n",
            "Test Score: 2.693 \n",
            "\n",
            "Execution time: 56.392 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GraphSAGE"
      ],
      "metadata": {
        "id": "RrqCvOwSHhe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGEConv(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv, self).__init__()\n",
        "        # A linear submodule for projecting the input and neighbor feature to the output.\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            # update_all is a message passing API.\n",
        "            g.update_all(\n",
        "                message_func=fn.copy_u(\"h\", \"m\"),\n",
        "                reduce_func=fn.mean(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "LsAdpGZTEz10"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphSAGE1(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "G1CNCOXXHlNS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = GraphSAGE1(config, global_size, num_tasks)"
      ],
      "metadata": {
        "id": "NbNpk0psHn6P"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate(model_3)\n",
        "test_evaluate(model_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQMXylbFHpYv",
        "outputId": "1b6f6d84-5684-48c8-eb1e-ccac009bfced"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint!\n",
            "Epoch: 1/100 | Training Loss: 1.004 | Valid Score: 4.383\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.383 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 2/100 | Training Loss: 0.989 | Valid Score: 4.350\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.350 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 3/100 | Training Loss: 0.978 | Valid Score: 4.322\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 4.322 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 4/100 | Training Loss: 0.967 | Valid Score: 4.298\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 4.298 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 5/100 | Training Loss: 0.954 | Valid Score: 4.279\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 4.279 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 6/100 | Training Loss: 0.943 | Valid Score: 4.259\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 4.259 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 7/100 | Training Loss: 0.930 | Valid Score: 4.242\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 4.242 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 8/100 | Training Loss: 0.923 | Valid Score: 4.228\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 4.228 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 9/100 | Training Loss: 0.914 | Valid Score: 4.212\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 4.212 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 10/100 | Training Loss: 0.903 | Valid Score: 4.201\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 4.201 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 11/100 | Training Loss: 0.875 | Valid Score: 4.184\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 4.184 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 12/100 | Training Loss: 0.883 | Valid Score: 4.180\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 4.180 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 13/100 | Training Loss: 0.868 | Valid Score: 4.168\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 4.168 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 14/100 | Training Loss: 0.862 | Valid Score: 4.155\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 4.155 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 15/100 | Training Loss: 0.850 | Valid Score: 4.150\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 4.150 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 16/100 | Training Loss: 0.839 | Valid Score: 4.139\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 4.139 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 17/100 | Training Loss: 0.826 | Valid Score: 4.120\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 4.120 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 18/100 | Training Loss: 0.816 | Valid Score: 4.114\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 4.114 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 19/100 | Training Loss: 0.804 | Valid Score: 4.105\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 4.105 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 20/100 | Training Loss: 0.792 | Valid Score: 4.101\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 4.101 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 21/100 | Training Loss: 0.780 | Valid Score: 4.091\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 4.091 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 22/100 | Training Loss: 0.768 | Valid Score: 4.082\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 4.082 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 23/100 | Training Loss: 0.757 | Valid Score: 4.065\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 4.065 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 24/100 | Training Loss: 0.745 | Valid Score: 4.052\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 4.052 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 25/100 | Training Loss: 0.734 | Valid Score: 4.048\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 4.048 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 26/100 | Training Loss: 0.723 | Valid Score: 4.036\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 4.036 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 27/100 | Training Loss: 0.709 | Valid Score: 4.032\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 4.032 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 28/100 | Training Loss: 0.700 | Valid Score: 4.022\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 4.022 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 29/100 | Training Loss: 0.691 | Valid Score: 4.017\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 4.017 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 30/100 | Training Loss: 0.680 | Valid Score: 4.006\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 4.006 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 31/100 | Training Loss: 0.670 | Valid Score: 3.998\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 3.998 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 32/100 | Training Loss: 0.662 | Valid Score: 3.982\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 3.982 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 33/100 | Training Loss: 0.652 | Valid Score: 3.983\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 3.982 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 34/100 | Training Loss: 0.644 | Valid Score: 3.982\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 3.982 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 35/100 | Training Loss: 0.633 | Valid Score: 3.978\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 3.978 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 36/100 | Training Loss: 0.627 | Valid Score: 3.953\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 3.953 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 37/100 | Training Loss: 0.618 | Valid Score: 3.943\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 3.943 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 38/100 | Training Loss: 0.611 | Valid Score: 3.938\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 3.938 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 39/100 | Training Loss: 0.604 | Valid Score: 3.943\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 3.938 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 40/100 | Training Loss: 0.597 | Valid Score: 3.934\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 3.934 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 41/100 | Training Loss: 0.587 | Valid Score: 3.927\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 3.927 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 42/100 | Training Loss: 0.583 | Valid Score: 3.911\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 3.911 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 43/100 | Training Loss: 0.575 | Valid Score: 3.911\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 3.911 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 0.569 | Valid Score: 3.914\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 3.911 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 45/100 | Training Loss: 0.563 | Valid Score: 3.904\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 3.904 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 46/100 | Training Loss: 0.556 | Valid Score: 3.888\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 3.888 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 47/100 | Training Loss: 0.548 | Valid Score: 3.888\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 3.888 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 48/100 | Training Loss: 0.543 | Valid Score: 3.883\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 3.883 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 49/100 | Training Loss: 0.538 | Valid Score: 3.875\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 3.875 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 50/100 | Training Loss: 0.532 | Valid Score: 3.870\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 3.870 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 51/100 | Training Loss: 0.524 | Valid Score: 3.870\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 3.870 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 52/100 | Training Loss: 0.521 | Valid Score: 3.863\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 3.863 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 53/100 | Training Loss: 0.517 | Valid Score: 3.851\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 3.851 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 54/100 | Training Loss: 0.510 | Valid Score: 3.848\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 3.848 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 55/100 | Training Loss: 0.506 | Valid Score: 3.840\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 3.840 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 56/100 | Training Loss: 0.500 | Valid Score: 3.849\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 3.840 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 57/100 | Training Loss: 0.495 | Valid Score: 3.839\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 3.839 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 58/100 | Training Loss: 0.490 | Valid Score: 3.833\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 3.833 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 59/100 | Training Loss: 0.484 | Valid Score: 3.819\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 3.819 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 60/100 | Training Loss: 0.480 | Valid Score: 3.816\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 3.816 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 61/100 | Training Loss: 0.476 | Valid Score: 3.815\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 3.815 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 62/100 | Training Loss: 0.472 | Valid Score: 3.813\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 3.813 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 63/100 | Training Loss: 0.467 | Valid Score: 3.810\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 3.810 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 64/100 | Training Loss: 0.463 | Valid Score: 3.803\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 3.803 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 65/100 | Training Loss: 0.458 | Valid Score: 3.797\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 3.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 0.410 | Valid Score: 3.801\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 3.797 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 67/100 | Training Loss: 0.449 | Valid Score: 3.803\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 3.797 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 68/100 | Training Loss: 0.445 | Valid Score: 3.795\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 3.795 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 69/100 | Training Loss: 0.440 | Valid Score: 3.793\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 3.793 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 70/100 | Training Loss: 0.437 | Valid Score: 3.791\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 3.791 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 71/100 | Training Loss: 0.433 | Valid Score: 3.789\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 3.789 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 72/100 | Training Loss: 0.425 | Valid Score: 3.787\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 3.787 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 73/100 | Training Loss: 0.425 | Valid Score: 3.779\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 3.779 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 74/100 | Training Loss: 0.421 | Valid Score: 3.778\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 3.778 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 75/100 | Training Loss: 0.417 | Valid Score: 3.777\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 3.777 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 76/100 | Training Loss: 0.413 | Valid Score: 3.777\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 3.777 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 77/100 | Training Loss: 0.408 | Valid Score: 3.773\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 3.773 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 78/100 | Training Loss: 0.405 | Valid Score: 3.771\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 3.771 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 79/100 | Training Loss: 0.403 | Valid Score: 3.767\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 3.767 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 80/100 | Training Loss: 0.399 | Valid Score: 3.769\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 3.767 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 81/100 | Training Loss: 0.395 | Valid Score: 3.764\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 3.764 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 82/100 | Training Loss: 0.392 | Valid Score: 3.762\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 3.762 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 83/100 | Training Loss: 0.388 | Valid Score: 3.761\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 3.761 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 84/100 | Training Loss: 0.385 | Valid Score: 3.760\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 3.760 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 85/100 | Training Loss: 0.381 | Valid Score: 3.761\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 3.760 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 86/100 | Training Loss: 0.378 | Valid Score: 3.758\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 3.758 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 87/100 | Training Loss: 0.375 | Valid Score: 3.758\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 3.758 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 88/100 | Training Loss: 0.372 | Valid Score: 3.755\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 3.755 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 89/100 | Training Loss: 0.369 | Valid Score: 3.752\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 3.752 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 90/100 | Training Loss: 0.366 | Valid Score: 3.754\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 3.752 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 91/100 | Training Loss: 0.363 | Valid Score: 3.753\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 3.752 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 92/100 | Training Loss: 0.360 | Valid Score: 3.755\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 3.752 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 93/100 | Training Loss: 0.358 | Valid Score: 3.754\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 3.752 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 94/100 | Training Loss: 0.354 | Valid Score: 3.756\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 3.752 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 95/100 | Training Loss: 0.351 | Valid Score: 3.752\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 3.752 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 96/100 | Training Loss: 0.349 | Valid Score: 3.752\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 3.752 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 97/100 | Training Loss: 0.346 | Valid Score: 3.751\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 3.751 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 98/100 | Training Loss: 0.341 | Valid Score: 3.756\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 3.751 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 99/100 | Training Loss: 0.340 | Valid Score: 3.751\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 3.751 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 100/100 | Training Loss: 0.338 | Valid Score: 3.753\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 3.751 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 3.751 \n",
            "\n",
            "Test Score: 2.462 \n",
            "\n",
            "Execution time: 101.185 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GraphSAGE with 4 layers and batch normalization and dropouts."
      ],
      "metadata": {
        "id": "dZkYdYheICNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphSAGE2(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size)\n",
        "        self.bn1 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.bn2 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.hidden_size)\n",
        "        self.bn3 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.dropout3 = nn.Dropout(0.2)\n",
        "\n",
        "        self.conv4 = SAGEConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = self.bn1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout1(h)\n",
        "\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = self.bn2(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout2(h)\n",
        "\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = self.bn3(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout3(h)\n",
        "\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "xqTfD5mXHrp1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = GraphSAGE2(config, global_size, num_tasks)"
      ],
      "metadata": {
        "id": "CSyoMhxrIM_T"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate(model_4)\n",
        "test_evaluate(model_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8hVWJ99IPJ3",
        "outputId": "41f6d713-7935-44a2-b091-df5d54186f57"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint!\n",
            "Epoch: 1/100 | Training Loss: 1.042 | Valid Score: 4.343\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.343 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 2/100 | Training Loss: 0.878 | Valid Score: 4.308\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.308 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 3/100 | Training Loss: 0.793 | Valid Score: 4.261\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 4.261 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 4/100 | Training Loss: 0.695 | Valid Score: 4.190\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 4.190 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 5/100 | Training Loss: 0.651 | Valid Score: 4.123\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 4.123 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 6/100 | Training Loss: 0.595 | Valid Score: 4.051\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 4.051 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 7/100 | Training Loss: 0.571 | Valid Score: 3.983\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 3.983 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 8/100 | Training Loss: 0.523 | Valid Score: 3.923\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 3.923 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 9/100 | Training Loss: 0.497 | Valid Score: 3.890\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 3.890 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 10/100 | Training Loss: 0.471 | Valid Score: 3.858\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 3.858 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 11/100 | Training Loss: 0.467 | Valid Score: 3.880\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 3.858 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 12/100 | Training Loss: 0.456 | Valid Score: 3.892\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 3.858 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 13/100 | Training Loss: 0.433 | Valid Score: 3.877\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 3.858 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 14/100 | Training Loss: 0.384 | Valid Score: 3.856\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 3.856 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 15/100 | Training Loss: 0.386 | Valid Score: 3.867\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 3.856 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 16/100 | Training Loss: 0.367 | Valid Score: 3.834\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 3.834 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 17/100 | Training Loss: 0.360 | Valid Score: 3.832\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 3.832 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 18/100 | Training Loss: 0.382 | Valid Score: 3.838\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 3.832 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 19/100 | Training Loss: 0.365 | Valid Score: 3.849\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 3.832 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 20/100 | Training Loss: 0.356 | Valid Score: 3.824\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 3.824 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 21/100 | Training Loss: 0.340 | Valid Score: 3.814\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 3.814 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 22/100 | Training Loss: 0.321 | Valid Score: 3.795\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 3.795 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 23/100 | Training Loss: 0.312 | Valid Score: 3.779\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 3.779 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 24/100 | Training Loss: 0.313 | Valid Score: 3.810\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 3.779 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 25/100 | Training Loss: 0.309 | Valid Score: 3.846\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 3.779 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 26/100 | Training Loss: 0.303 | Valid Score: 3.875\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 3.779 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 27/100 | Training Loss: 0.306 | Valid Score: 3.839\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 3.779 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 28/100 | Training Loss: 0.282 | Valid Score: 3.887\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 3.779 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 29/100 | Training Loss: 0.309 | Valid Score: 3.874\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 3.779 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 30/100 | Training Loss: 0.268 | Valid Score: 3.809\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 3.779 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 31/100 | Training Loss: 0.265 | Valid Score: 3.795\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 3.779 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 32/100 | Training Loss: 0.265 | Valid Score: 3.767\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 3.767 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 33/100 | Training Loss: 0.266 | Valid Score: 3.728\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 3.728 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.278 | Valid Score: 3.735\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 3.728 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 35/100 | Training Loss: 0.250 | Valid Score: 3.726\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 3.726 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 36/100 | Training Loss: 0.246 | Valid Score: 3.742\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 3.726 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 37/100 | Training Loss: 0.269 | Valid Score: 3.742\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 3.726 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 38/100 | Training Loss: 0.237 | Valid Score: 3.664\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 3.664 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 39/100 | Training Loss: 0.231 | Valid Score: 3.660\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 3.660 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 0.227 | Valid Score: 3.707\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 3.660 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 41/100 | Training Loss: 0.236 | Valid Score: 3.742\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 3.660 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 42/100 | Training Loss: 0.225 | Valid Score: 3.705\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 3.660 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 43/100 | Training Loss: 0.239 | Valid Score: 3.574\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 3.574 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 44/100 | Training Loss: 0.227 | Valid Score: 3.509\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 3.509 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 45/100 | Training Loss: 0.206 | Valid Score: 3.468\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 3.468 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 46/100 | Training Loss: 0.200 | Valid Score: 3.449\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 3.449 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 47/100 | Training Loss: 0.228 | Valid Score: 3.444\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 3.444 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 48/100 | Training Loss: 0.209 | Valid Score: 3.428\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 3.428 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 49/100 | Training Loss: 0.218 | Valid Score: 3.344\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 3.344 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 50/100 | Training Loss: 0.229 | Valid Score: 3.265\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 3.265 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 51/100 | Training Loss: 0.216 | Valid Score: 3.298\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 3.265 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 52/100 | Training Loss: 0.195 | Valid Score: 3.270\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 3.265 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 53/100 | Training Loss: 0.190 | Valid Score: 3.205\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 3.205 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 54/100 | Training Loss: 0.189 | Valid Score: 3.170\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 3.170 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 55/100 | Training Loss: 0.198 | Valid Score: 3.167\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 3.167 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 56/100 | Training Loss: 0.188 | Valid Score: 3.115\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 3.115 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 0.193 | Valid Score: 3.130\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 3.115 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 58/100 | Training Loss: 0.176 | Valid Score: 3.151\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 3.115 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 59/100 | Training Loss: 0.194 | Valid Score: 3.100\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 3.100 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 60/100 | Training Loss: 0.204 | Valid Score: 2.949\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 2.949 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 61/100 | Training Loss: 0.173 | Valid Score: 2.879\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 2.879 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 62/100 | Training Loss: 0.207 | Valid Score: 2.939\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 2.879 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 63/100 | Training Loss: 0.183 | Valid Score: 2.995\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 2.879 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 64/100 | Training Loss: 0.170 | Valid Score: 2.933\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 2.879 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 65/100 | Training Loss: 0.181 | Valid Score: 2.947\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 2.879 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 66/100 | Training Loss: 0.172 | Valid Score: 2.904\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 2.879 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 67/100 | Training Loss: 0.181 | Valid Score: 2.898\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 2.879 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 68/100 | Training Loss: 0.176 | Valid Score: 2.817\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 2.817 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 69/100 | Training Loss: 0.164 | Valid Score: 2.810\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 2.810 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 70/100 | Training Loss: 0.168 | Valid Score: 2.800\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 2.800 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 71/100 | Training Loss: 0.208 | Valid Score: 2.862\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 2.800 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 72/100 | Training Loss: 0.176 | Valid Score: 2.797\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 2.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 73/100 | Training Loss: 0.185 | Valid Score: 2.822\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 2.797 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 74/100 | Training Loss: 0.146 | Valid Score: 2.818\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 2.797 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 75/100 | Training Loss: 0.159 | Valid Score: 2.837\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 2.797 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 76/100 | Training Loss: 0.155 | Valid Score: 2.833\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 2.797 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 77/100 | Training Loss: 0.176 | Valid Score: 2.760\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 2.760 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 78/100 | Training Loss: 0.162 | Valid Score: 2.706\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 2.706 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 79/100 | Training Loss: 0.148 | Valid Score: 2.671\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 2.671 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 80/100 | Training Loss: 0.177 | Valid Score: 2.680\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 2.671 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 81/100 | Training Loss: 0.150 | Valid Score: 2.674\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 2.671 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 82/100 | Training Loss: 0.166 | Valid Score: 2.665\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 2.665 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 83/100 | Training Loss: 0.167 | Valid Score: 2.688\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 2.665 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 84/100 | Training Loss: 0.137 | Valid Score: 2.703\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 2.665 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 85/100 | Training Loss: 0.156 | Valid Score: 2.670\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 2.665 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 86/100 | Training Loss: 0.146 | Valid Score: 2.664\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 2.664 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 87/100 | Training Loss: 0.157 | Valid Score: 2.667\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 2.664 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 88/100 | Training Loss: 0.171 | Valid Score: 2.722\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 2.664 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 89/100 | Training Loss: 0.154 | Valid Score: 2.675\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 2.664 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 90/100 | Training Loss: 0.145 | Valid Score: 2.710\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 2.664 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 91/100 | Training Loss: 0.124 | Valid Score: 2.714\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 2.664 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 92/100 | Training Loss: 0.145 | Valid Score: 2.721\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 2.664 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 93/100 | Training Loss: 0.158 | Valid Score: 2.659\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 2.659 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 94/100 | Training Loss: 0.146 | Valid Score: 2.577\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 2.577 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 95/100 | Training Loss: 0.144 | Valid Score: 2.527\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 2.527 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 96/100 | Training Loss: 0.157 | Valid Score: 2.581\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 2.527 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 97/100 | Training Loss: 0.140 | Valid Score: 2.621\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 2.527 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 98/100 | Training Loss: 0.140 | Valid Score: 2.599\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 2.527 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 99/100 | Training Loss: 0.140 | Valid Score: 2.654\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 2.527 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 100/100 | Training Loss: 0.144 | Valid Score: 2.684\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 2.527 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 2.527 \n",
            "\n",
            "Test Score: 1.864 \n",
            "\n",
            "Execution time: 148.551 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom GNN"
      ],
      "metadata": {
        "id": "p-j9ueVoJ5eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomGraphConv(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(CustomGraphConv, self).__init__()\n",
        "        # A linear submodule for projecting the input and neighbor feature to the output.\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            # update_all is a message passing API.\n",
        "            g.update_all(\n",
        "                message_func=fn.u_add_v(\"h\", \"h\", \"m\"),\n",
        "                reduce_func=fn.mean(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "lq-hnMN6J2a5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = CustomGraphConv(self.node_feature_size, self.hidden_size)\n",
        "        self.bn1 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.conv2 = CustomGraphConv(self.hidden_size, self.hidden_size)\n",
        "        self.bn2 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.conv3 = CustomGraphConv(self.hidden_size, self.hidden_size)\n",
        "        self.bn3 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.dropout3 = nn.Dropout(0.2)\n",
        "\n",
        "        self.conv4 = CustomGraphConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = self.bn1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout1(h)\n",
        "\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = self.bn2(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout2(h)\n",
        "\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = self.bn3(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout3(h)\n",
        "\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "eV8VWUJPKEBo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = GNN(config, global_size, num_tasks)"
      ],
      "metadata": {
        "id": "UbfXMxzpKGyG"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate(model_5)\n",
        "test_evaluate(model_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTsM-66aKKiM",
        "outputId": "6deb7a04-dd55-4567-f268-0d3084405247"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint!\n",
            "Epoch: 1/100 | Training Loss: 1.269 | Valid Score: 4.363\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 4.363 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 1.000 | Valid Score: 4.446\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 4.363 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 0.851 | Valid Score: 4.367\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 4.363 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 4/100 | Training Loss: 0.751 | Valid Score: 4.132\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 4.132 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 5/100 | Training Loss: 0.651 | Valid Score: 3.862\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 3.862 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 6/100 | Training Loss: 0.611 | Valid Score: 3.722\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 3.722 \n",
            "\n",
            "Save checkpoint!\n",
            "Epoch: 7/100 | Training Loss: 0.583 | Valid Score: 3.652\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 8/100 | Training Loss: 0.524 | Valid Score: 3.688\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 9/100 | Training Loss: 0.507 | Valid Score: 3.784\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 10/100 | Training Loss: 0.476 | Valid Score: 3.842\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 11/100 | Training Loss: 0.460 | Valid Score: 3.873\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 12/100 | Training Loss: 0.490 | Valid Score: 3.864\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 13/100 | Training Loss: 0.483 | Valid Score: 3.828\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 14/100 | Training Loss: 0.418 | Valid Score: 3.823\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 15/100 | Training Loss: 0.406 | Valid Score: 3.807\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 16/100 | Training Loss: 0.459 | Valid Score: 3.752\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 17/100 | Training Loss: 0.454 | Valid Score: 3.753\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 3.652 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 3.652 \n",
            "\n",
            "Test Score: 2.727 \n",
            "\n",
            "Execution time: 780.890 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aMYUCfl5IQst"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}